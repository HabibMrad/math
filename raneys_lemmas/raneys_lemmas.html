<!doctype html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Notes on Raney's Lemmas</title>
    <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
    <style>
      body     { font-size: 120%; }
      table    { margin: auto; }
      code     { white-space: pre; }
      q        { quotes: "“" "”" "‘" "’"; }
      h1       { font-size: 1.5em; }
      h2       { font-size: 1.17em; }
      img      { width: 760px; }
      .title   { font-size: 2em; font-weight: bold; }
      .author  { color: #AAA; line-height: 150%; }
      .date    { color: #AAA; line-height: 150%; font-size: 0.8em; }
      .main    { width: 760px; margin: auto; }
      .caption { text-align: center; }
    </style>
  </head>
  <body>
    <div class="main">
      <div class="title">Notes on Raney's Lemmas</div>
      <div class="author">Tyler Neylon</div>
      <div class="date">251.2015</div>
      <p>In a 1960 paper, George Raney proved the first two lemmas below; the lemmas suppose we have a finite sequence of numbers meeting certain constraints, and provide the number of cycle shifts that contain all-positive partial sums <span class="citation">(Raney 1960)</span>.</p>
      <p>These notes expand on the ideas behind these lemmas. The final section of these notes discusses cyclic shifts for finite sequences of independent, uniformly random values; as far as I know, the work in that section is new.</p>
      <p>I personally learned of these lemmas in chapter 7 of the book <em>Concrete Mathematics</em> <span class="citation">(Knuth, Patashnik, and Graham 1998)</span>, which explores their applications to generating functions. The presentation of the lemmas here is based on the presentation in <em>Concrete Mathematics</em> rather than on Raney's original paper.</p>
      <h1 id="integer-sequences"><span class="header-section-number">1</span> Integer sequences</h1>
      <p><strong>Lemma 1</strong>  <em>Suppose <span class="math">\(\sum_{i=1}^n x_i = 1\)</span>, where all <span class="math">\(x_i\in\mathbb{Z}\)</span>. Extend the sequence by letting <span class="math">\(x_{n+p}=x_p\)</span> for <span class="math">\(1\le p\le n\)</span>. Then there is a unique <span class="math">\(j\)</span>, <span class="math">\(1 \le j \le n\)</span>, such that</em></p>
      <p><span class="math">\[\sum_{i=j}^{j+k-1} x_i &gt; 0; \quad 1 \le k \le n.\]</span></p>
      <hr />
      <p>Intuitively, we can think of such an index <span class="math">\(j\)</span> as a cyclic shift of the sequence that has partial sums that are all positive.</p>
      <p>For example, the finite sequence <span class="math">\(\langle x_1, \ldots, x_5\rangle = \langle 3, -2, 4, -1, 1 \rangle\)</span> offers <span class="math">\(j=5\)</span> as the unique shift providing <span class="math">\(\langle x_5, x_6=x_1, \ldots, x_9=x_4\rangle = \langle 1, 3, -2, 4, -5\rangle\)</span> with partial sums <span class="math">\(\langle 1, 4, 2, 6, 1\rangle\)</span> that are all positive.</p>
      <p><strong>Definitions</strong>  Given a sequence <span class="math">\(\langle x_1, \ldots, x_n\rangle\)</span>, it's useful to say that an index <span class="math">\(i \in \{1,\ldots, n\}\)</span> is a <em>positive-sum shift</em> if and only if the partial sums of <span class="math">\(\langle x_i, \ldots, x_n, x_1, \ldots, x_{i-1}\rangle\)</span> are all positive. Since these notes focus on finite sequences, we'll implicitly use arbitrary indexes <span class="math">\(x_j, j\in\mathbb{Z}\)</span>, to refer to <span class="math">\(x_k\)</span> with <span class="math">\(k\in \{1, \ldots, n\}, k\equiv j \pmod n\)</span>.</p>
      <p>We'll use the subscript-free letter <span class="math">\(x\)</span> to denote an entire finite sequence <span class="math">\(\langle x_1, \ldots, x_n\rangle\)</span>. We'll write <span class="math">\(\sigma(x)\)</span> to indicate the number of indexes of <span class="math">\(x\)</span> that are positive-sum shifts.</p>
      <p>We can now concisely state a related result proved by Raney:</p>
      <p><strong>Lemma 2</strong>  <em>Suppose <span class="math">\(\sum_{i=1}^nx_i=\ell\)</span>, where <span class="math">\(x_i\in\mathbb{Z}\)</span> and <span class="math">\(x_i \le 1\)</span> for all <span class="math">\(i\)</span>. Then <span class="math">\(\sigma(x) = \ell\)</span>; that is, exactly <span class="math">\(\ell\)</span> indexes in <span class="math">\(\{1, \ldots, n\}\)</span> are positive-sum shifts.</em></p>
      <hr />
      <p>For example, let <span class="math">\(\langle x_1, \ldots, x_8\rangle = \langle -2, 1, 1, 0, -1, 1, 1, 1\rangle\)</span>. Then <span class="math">\(\sum x_i = 2\)</span>, and <span class="math">\(x_2, x_6\)</span> are the only positive-sum shifts:</p>
      <table>
      <thead>
      <tr class="header">
      <th align="left">shift</th>
      <th align="left">partial sums</th>
      </tr>
      </thead>
      <tbody>
      <tr class="odd">
      <td align="left"><span class="math">\(\langle x_2, \ldots\rangle = \langle 1, 1, 0, -1, 1, 1, 1, -2\rangle\quad\)</span></td>
      <td align="left"><span class="math">\(\langle 1, 2, 2, 1, 2, 3, 4, 2\rangle\)</span></td>
      </tr>
      <tr class="even">
      <td align="left"><span class="math">\(\langle x_6, \ldots\rangle = \langle 1, 1, 1, -2, 1, 1, 0, -1\rangle\quad\)</span></td>
      <td align="left"><span class="math">\(\langle 1, 2, 3, 1, 2, 3, 3, 2\rangle\)</span></td>
      </tr>
      </tbody>
      </table>
      <p>Note that lemma 2 is not a strict generalization of lemma 1 as it adds the condition <span class="math">\(x_i \le 1\)</span>. This condition is necessary for lemma 2; without it we may have, for example, the one-element sequence <span class="math">\(x = \langle 2\rangle\)</span> with sum <span class="math">\(\ell = 2\)</span> and <span class="math">\(\sigma(x) = 1\)</span>.</p>
      <p>Rather than proving the above two lemmas directly, we'll jump to the general case of real sequences <span class="math">\(x\)</span> and prove strictly more general bounds on <span class="math">\(\sigma(x)\)</span> in that context.</p>
      <h1 id="real-sequences"><span class="header-section-number">2</span> Real sequences</h1>
      <p>In a moment we'll prove a general guarantee that <span class="math">\(\sum x_i &gt; 0 \Rightarrow \sigma(x) \ge 1\)</span>. In the context of a sequence <span class="math">\(x\)</span>, it will be useful to write <span class="math">\(s_i\)</span> to denote the <span class="math">\(i^\mathrm{th}\)</span> partial sum of <span class="math">\(x\)</span>; that is, <span class="math">\(s_0 = 0\)</span>, and <span class="math">\[ s_i = \sum_{j=1}^i x_j, \quad \text{for } i \ge 1. \]</span> We can define <span class="math">\(s_i\)</span> for <span class="math">\(i &gt; n\)</span> using the implicitly periodic sequence characterized by <span class="math">\(x_{n + i} = x_i\)</span>.</p>
      <p><strong>Property 3</strong>  <em>Suppose <span class="math">\(\sum_{i=1}^nx_i &gt; 0\)</span>, where <span class="math">\(x_i\in\mathbb{R}\)</span>. Let <span class="math">\(s_i\)</span> denote the <span class="math">\(i^\mathrm{th}\)</span> partial sum of <span class="math">\(x\)</span>, and let <span class="math">\(j\)</span> be the largest index in <span class="math">\(\{1, \ldots, n\}\)</span> with <span class="math">\(s_{j-1} = \min_{0\le i &lt; n} s_i\)</span>. Then <span class="math">\(j\)</span> is a positive-sum shift.</em></p>
      <hr />
      <p><strong>Proof</strong>  Let <span class="math">\[s&#39;_i = \sum_{k=j}^{j+i-1}x_k\]</span> denote the <span class="math">\(i^\mathrm{th}\)</span> partial sum of the shifted sequence <span class="math">\(\langle x_j, \ldots, x_{j+n-1}\rangle\)</span>. Then, for <span class="math">\(1 \le i \le n\)</span>, <span class="math">\[s&#39;_i = s_{j+i-1} - s_{j-1}
      \begin{cases}
      &gt; 0 \text{ (by definition of $j$)} &amp; \text{when } j+i-1 &lt; n \\
      = s_n + s_{j+i-1-n}-s_{j-1} \ge s_n &gt; 0 &amp; \text{when } j+i-1 \ge n. \\
      \end{cases}\]</span> <span class="math">\(\Box\)</span></p>
      <p>Now we can assume without loss of generality that any sequence of real numbers <span class="math">\(\langle x_1, \ldots, x_n\rangle\)</span> with <span class="math">\(\sum x_i &gt; 0\)</span> is already shifted so that all its partial sums <span class="math">\(s_i &gt; 0\)</span> for <span class="math">\(i &gt; 0\)</span>. As we'll see in the next property, this assumption allows us to provide a nice general expression for <span class="math">\(\sigma(x)\)</span>. This expression depends on the set <span class="math">\(S(x)\)</span>, defined as <span class="math">\(\{\min_{j \le i \le n} s_i\; \big|\; 1 \le j \le n \}\)</span> for any finite sequence <span class="math">\(x\)</span> with <span class="math">\(i^\text{th}\)</span> partial sum <span class="math">\(s_i\)</span>.</p>
      <p><strong>Property 4</strong>  <em>Suppose that <span class="math">\(x\)</span> is a finite real sequence with <span class="math">\(i^\text{th}\)</span> partial sum <span class="math">\(s_i\)</span>, and that <span class="math">\(s_i &gt; 0\)</span> for all <span class="math">\(i &gt; 0\)</span>. Then</em></p>
      <p><span class="math">\[\sigma(x) = \#S(x) =
      \#\left\{\min_{j \le i \le n} s_i\; \big|\; 1 \le j \le n \right\}.\qquad(1)\]</span></p>
      <p><em>More specifically, an index <span class="math">\(j\)</span> with <span class="math">\(1 \le j \le n\)</span> is a positive-sum shift iff</em></p>
      <p><span class="math">\[s_{j-1} &lt; s_i \;\forall i: j\le i \le n.\qquad(2)\]</span></p>
      <hr />
      <p><strong>Proof</strong>  We'll start by supposing we have an index <span class="math">\(j\)</span> with <span class="math">\(1 \le j \le n\)</span> and <span class="math">\(s_{j-1} &lt; s_i\)</span> for all <span class="math">\(i\)</span> with <span class="math">\(j \le i \le n\)</span>; our goal is to show that such a <span class="math">\(j\)</span> must be a positive-sum shift. Our approach will be similar to the proof of property 3.</p>
      <p>Let <span class="math">\(s&#39;_i\)</span> denote the <span class="math">\(i^\text{th}\)</span> partial sum of <span class="math">\(\langle x_j, \ldots, x_{j+n-1}\rangle\)</span>: <span class="math">\[s&#39;_i = \sum_{k=j}^{j+i-1}x_k.\]</span> Then <span class="math">\[s&#39;_i = s_{j+i-1} - s_{j-1} \begin{cases}
      &gt; 0 &amp; \text{if } j+i-1 \le n, \\
      = s_{j+i-1-n} + s_n - s_{j-1} &gt; 0 &amp; \text{if } j+i-1 &gt; n; \\
      \end{cases}\]</span> the last inequality follows since <span class="math">\(s_{j+i-1-n} &gt; 0\)</span> and <span class="math">\(s_n &gt; s_{j-1}\)</span>.</p>
      <p>On the other hand, if <span class="math">\(s_{j-1}\ge s_i\)</span> for some <span class="math">\(i,j\)</span> with <span class="math">\(1\le j\le i\le n\)</span>, then <span class="math">\(s&#39;_{i-j+1}=s_i-s_{j-1}\le 0\)</span>, so that <span class="math">\(j\)</span> isn't a positive-sum shift. This completes the proof of the last part of the property.</p>
      <p>Now let's verify that the set <span class="math">\(S = S(x)\)</span> from (1) has size <span class="math">\(\sigma(x)\)</span>.</p>
      <p>Let <span class="math">\(j_1, \ldots, j_k\)</span> be all the positive-sum shifts with <span class="math">\(1 &lt; j_i \le n\)</span>; note that <span class="math">\(k = \sigma(x) - 1\)</span> since the trivial shift index 1 has been excluded. Let <span class="math">\(T = \{s_{j_1 - 1}, \ldots, s_{j_k - 1}, s_n\}\)</span>.</p>
      <p>Notice that <span class="math">\(j=n+1\)</span> trivially meets condition (2); combine this with the first part of the proof to see that all elements of <span class="math">\(T\)</span> meet condition (2). This guarantees that all the elements are unique, so that <span class="math">\(|T| = \sigma(x)\)</span>. This also means that <span class="math">\(T \subset S\)</span>. Finally, observe that, for any <span class="math">\(s_j \in S\)</span>, there's a largest index <span class="math">\(j&#39;\)</span> with <span class="math">\(1\le j&#39; \le n\)</span> and <span class="math">\(s_{j&#39;} = s_j\)</span>; this index <span class="math">\(j&#39;\)</span> meets condition (2), so that <span class="math">\(S\subset T\)</span>, confirming that <span class="math">\(|S| = |T| = \sigma(x)\)</span>. <span class="math">\(\Box\)</span></p>
      <p>Property 4 lends itself to a nice visual intuition. Consider the example sequence <span class="math">\(\langle 2, -1, 2, 2, -3, 2, 1, 1, -1, -2\rangle\)</span> of length <span class="math">\(n=10\)</span>. Below is the line graph of its partial sums, starting with <span class="math">\(s_0=0\)</span>.</p>
      <div class="figure">
      <img src="images/figure1.png" alt="Line graph of the partial sums s_i of the example sequence." />
      <p class="caption"><em>Line graph of the partial sums <span class="math">\(s_i\)</span> of the example sequence.</em></p>
      </div>
      <p>Imagine an observer standing far to the right of the graph and looking directly to the left so they can only see along a perfectly horizontal line of sight. Below <span class="math">\(s_n\)</span>, they can only see the three points <span class="math">\(s_0\)</span>, <span class="math">\(s_2\)</span>, and <span class="math">\(s_5\)</span>. These are exactly the partial sums meeting condition (2), so that they correspond directly to all the positive-sum shifts of <span class="math">\(x\)</span>, which have indexes 1, 3, and 6.</p>
      <p>This visual intuition — that points visible-from-the-right and below <span class="math">\(s_n\)</span> correspond exactly to the positive-sum shifts — extends to any sequence meeting the suppositions of property 4.</p>
      <p>It's now possible to prove a simple general upper and lower bound for <span class="math">\(\sigma(x)\)</span> in the case that each <span class="math">\(x_i\)</span> is an integer. We'll see below that these bounds provide both lemmas 1 and 2 as corollaries.</p>
      <p><strong>Property 5</strong>  <em>Suppose we have a finite integer sequence <span class="math">\(x = \langle x_1, \ldots, x_n\rangle\)</span> with <span class="math">\(s_n &gt; 0\)</span>. Let <span class="math">\(m = \max_i x_i\)</span>. Then <span class="math">\[
      \lceil s_n / m \rceil \le \sigma(x) \le s_n.
      \]</span></em></p>
      <p><strong>Proof idea</strong>  Here is the informal intuition behind the proof: We'll start by noticing that, for sum-positive <span class="math">\(x\)</span>, <span class="math">\(S(x) \subset (0, s_n]\)</span>; this is the basis used for the upper bound. The lower bound is based on the idea that each jump upwards from one <span class="math">\(s_i\in S(x)\)</span> to the next <span class="math">\(s_j\in S(x)\)</span> is limited by distance <span class="math">\(m\)</span>. The smallest element in <span class="math">\(S(x)\)</span> can be at most <span class="math">\(m\)</span> above <span class="math">\(s_0=0\)</span>, and the largest is necessarily <span class="math">\(s_n\)</span>, so that there must be at least <span class="math">\(s_n/m\)</span> elements between the extremes.</p>
      <p><strong>Proof</strong>  Notice that we can work with any cyclic shift <span class="math">\(x&#39;\)</span> of <span class="math">\(x\)</span> without changing <span class="math">\(s_n\)</span> or <span class="math">\(m\)</span>. Thus, using property 3, we can assume without loss of generality that <span class="math">\(s_i &gt; 0\)</span> for <span class="math">\(i &gt; 0\)</span>.</p>
      <p>Next, we can bound the elements of <span class="math">\(S(x)\)</span> via <span class="math">\[
      0 &lt; \min_{j\le i\le n}s_i \le s_n
      \]</span> for all <span class="math">\(j\)</span> with <span class="math">\(1\le j \le n\)</span>. So all elements of <span class="math">\(S(x)\)</span> are in the range <span class="math">\((0, s_n]\)</span>, and are integers. Hence <span class="math">\(\#S(x) \le s_n\)</span>, completing the proof of the upper bound.</p>
      <p>Toward the lower bound, let's suppose that <span class="math">\(S(x) = \{s_{j_1}, \ldots, s_{j_k}\}\)</span> with each <span class="math">\(s_{j_i}\)</span> meeting condition (2) and <span class="math">\(0 &lt; s_{j_i} &lt; s_{j_{i+1}}\)</span>. We know such <span class="math">\(s_{j_i}\)</span> exist as they are simply those partial sums in <span class="math">\(s_{j_i}\in S(x)\)</span> chosen so that <span class="math">\(j_i = \max_{1\le k\le n} \{k: s_k = s_{j_i}\}\)</span>.</p>
      <p>By our definition of <span class="math">\(s_{j_i}\)</span>, we have <span class="math">\[
      s_{j_i} = \min_{j_i \le k \le n}s_k
      \;\text{ and }\;
      s_{j_{i+1}} = \min_{j_i+1 \le k \le n}s_k.
      \]</span> This means that <span class="math">\[s_{j_{i+1}} - s_{j_i} = \min_{j_i+1 \le k \le n}s_k - s_{j_i} \le
      s_{j_i+1} - s_{j_i} \le
      m.\]</span></p>
      <p>Note that <span class="math">\(s_{j_k}=s_n\)</span> so that <span class="math">\(s_n - s_{j_{k-1}} \le m \Rightarrow s_{j_{k-1}} \ge s_n - m\)</span>. This can be extended to see that <span class="math">\(s_{j_{k-2}} \ge s_n - 2m\)</span>, and in general that <span class="math">\[
      s_{j_{k-p}} \ge s_n - pm.
      \]</span></p>
      <p>Our definition of <span class="math">\(m\)</span> gives us that <span class="math">\(s_{j_1} \le m\)</span>, so <span class="math">\(m \ge s_{j_1} \ge s_n - (k-1)m\)</span>, from which we can derive that <span class="math">\[
      1 \ge s_n/m - (k - 1)
      \quad \Rightarrow \quad
      k \ge s_n/m
      \quad \Rightarrow \quad
      k \ge \lceil s_n/m \rceil;
      \]</span> the last inequality uses the fact that <span class="math">\(k = \sigma(x)\)</span> is an integer. This completes the proof. <span class="math">\(\Box\)</span></p>
      <p><strong>The Contraction Perspective</strong></p>
      <p>Next we'll consider a contraction operation that may shorten a sequence <span class="math">\(x\)</span> while preserving <span class="math">\(\sigma(x)\)</span>.</p>
      <p>Call a sequence <span class="math">\(x = \langle x_1, \ldots, x_n\rangle\)</span> <em>sum-positive</em> iff <span class="math">\(s_i &gt; 0\)</span> when <span class="math">\(i &gt; 0\)</span>. We'll say that a sequence <span class="math">\(x&#39; = \langle x&#39;_1, \ldots, x&#39;_{n-1} \rangle\)</span> is a <em>contraction</em> of the length-<span class="math">\(n\)</span> sum-positive sequence <span class="math">\(x\)</span> iff there is some index <span class="math">\(j\)</span> so that <span class="math">\(x_{j + 1} \le 0\)</span> and, for <span class="math">\(1 \le i \le n-1\)</span>, <span class="math">\[x&#39;_i = \begin{cases}
      x_i &amp; \text{if } i &lt; j, \\
      x_i + x_{i + 1} &amp; \text{if } i = j, \text{and} \\
      x_{i + 1} &amp; \text{if } i &gt; j.
      \end{cases}\]</span></p>
      <p>For example. <span class="math">\(x&#39; = \langle 2, -1, 2\rangle\)</span> is a contraction of <span class="math">\(x = \langle 3, -1, -1, 2\rangle\)</span> since the sequences are same except for the replacement of <span class="math">\(x_1, x_2\)</span> by their sum as <span class="math">\(x&#39;_1\)</span>, and <span class="math">\(x_2 = -1 \le 0\)</span>. The alternative sequence <span class="math">\(x&#39;&#39; = \langle 3, -1, 1\rangle\)</span> is <em>not</em> a contraction as it replaces <span class="math">\(x_3, x_4\)</span> with their sum <span class="math">\(x&#39;&#39;_3\)</span>, but <span class="math">\(x_4 = 2 &gt; 0\)</span>.</p>
      <p><strong>Property 6</strong>  <em>If <span class="math">\(x&#39;\)</span> is a contraction of <span class="math">\(x\)</span>, then <span class="math">\(x&#39;\)</span> is sum-positive and <span class="math">\(\sigma(x&#39;) = \sigma(x)\)</span>.</em></p>
      <p><strong>Proof</strong>  Let <span class="math">\(j\)</span> be the contracted index, so that <span class="math">\(x&#39;_j = x_j + x_{j + 1}\)</span> and <span class="math">\(x_{j + 1} \le 0\)</span>.</p>
      <p>Let <span class="math">\(s&#39;_i\)</span> denote the <span class="math">\(i^\text{th}\)</span> partial sum of <span class="math">\(x&#39;\)</span>. Then <span class="math">\[s&#39;_i = \begin{cases}
      s_i &amp; \text{if } 0 \le i &lt; j \\
      s_{i + 1} &amp; \text{if } j \le i \le n-1.
      \end{cases}\]</span></p>
      <p>So <span class="math">\(s&#39;_i &gt; 0\)</span> for <span class="math">\(0 &lt; i \le n - 1\)</span>, making <span class="math">\(x&#39;\)</span> sum-positive.</p>
      <p>Since <span class="math">\(x_{j+1} \le 0\)</span>, <span class="math">\(s_{j+1} \le s_j\)</span>. This means that <span class="math">\[
      \min_{k \le i \le n} s_i = \min_{k \le i \le n, i \ne j} s_i,
      \;\;\text{and}\;\;
      \min_{k \le i \le n} s&#39;_i = \begin{cases}
      \min_{k \le i \le n} s_i &amp; \text{if } k &lt; j, \text{ and} \\
      \min_{k+1 \le i \le n} s_i &amp; \text{if } k \ge j,\\
      \end{cases}
      \]</span> for all <span class="math">\(k\)</span> with <span class="math">\(1 \le k \le n\)</span>. This last equality ensures that <span class="math">\(S(x) = S(x&#39;)\)</span>, so that <span class="math">\(\sigma(x) = \sigma(x&#39;)\)</span> using property 4. This completes the proof. <span class="math">\(\Box\)</span></p>
      <p>As long as a sum-positive sequence <span class="math">\(x\)</span> has any element <span class="math">\(x_i \le 0\)</span>, we can apply a contraction to it to arrive at a shorter sequence. Thus, we can always apply a series of contractions to arrive at a sum-positive, length-<span class="math">\(k\)</span> sequence <span class="math">\(x&#39;\)</span> with all elements <span class="math">\(x&#39;_i &gt; 0\)</span>. All shifts of this <span class="math">\(x&#39;\)</span> are positive-sum shifts, so that <span class="math">\(\sigma(x&#39;)=k\)</span>, and thus <span class="math">\(\sigma(x)=k\)</span> as well. In other words, we can find <span class="math">\(\sigma(x)\)</span> by contracting <span class="math">\(x\)</span> until it can be contracted no more.</p>
      <p>To add both intuition and more detail to this process, think of any sum-positive sequence <span class="math">\(x\)</span> as consisting of subsequences starting with <span class="math">\(x_j\)</span> for each positive-sum shift index <span class="math">\(j\)</span>. For example, suppose sequence <span class="math">\(x\)</span> has positive-sum shift indexes 1, 3, and 4. Then <span class="math">\[
      \langle x_1, x_2, x_3, x_4, x_5, x_6\rangle =
      \langle x_1, x_2\rangle
      \langle x_3 \rangle
      \langle x_4, x_5, x_6 \rangle.
      \]</span></p>
      <p>Contractions effectively work within these subsequences. A contraction can never combine elements across a subsequence boundary because the first element of any subsequence must be positive. Our last proof showed that the set <span class="math">\(S(x)\)</span> is preserved by contraction. That proof also showed that the indexes <span class="math">\(j_1, \ldots, j_k\)</span> with <span class="math">\(\{s_{j_1}, \ldots, s_{j_k}\} = S(x)\)</span> are preserved as well, excepting a possible shift-by-one in the latter elements to account for the contraction. In other words, if an element <span class="math">\(x_j\)</span> begins a subsequence before a contraction, then it will be mapped to <span class="math">\(x&#39;_k\)</span> with either <span class="math">\(k=j\)</span> or <span class="math">\(k=j-1\)</span>, with <span class="math">\(x&#39;_k = x_j\)</span>, and with <span class="math">\(x&#39;_k\)</span> also acting as a positive-sum shift for <span class="math">\(x&#39;\)</span>.</p>
      <p>The final result of any maximal series of contractions is therefore deterministic: we must arrive at exactly the sequence of sums of the original subsequences. Using our last example sequence, we may make the following series of underlined contractions: <span class="math">\[
      \begin{array}{cccc}
      &amp;
      \langle x_1, x_2\rangle &amp;
      \langle x_3 \rangle &amp;
      \langle x_4, x_5, x_6 \rangle \\
      \rightarrow &amp;
      \langle x_1, x_2\rangle &amp;
      \langle x_3 \rangle &amp;
      \langle \underline{x_4 + x_5}, x_6 \rangle \\
      \rightarrow &amp;
      \langle \underline{x_1 + x_2}\rangle &amp;
      \langle x_3 \rangle &amp;
      \langle x_4 + x_5, x_6 \rangle \\
      \rightarrow &amp;
      \langle x_1 + x_2\rangle &amp;
      \langle x_3 \rangle &amp;
      \langle x_4 + \underline{x_5 + x_6} \rangle. \\
      \end{array}
      \]</span></p>
      <p>The final sequence has 3 positive elements, so we can't perform any more contractions. We have freedom in the order in which we execute those contractions, but the end result is independent of this order. Note that, although we've highlighted the subsequence structure here, we don't need to be aware of that structure to execute the contractions.</p>
      <h1 id="random-sequences"><span class="header-section-number">3</span> Random sequences</h1>
      <p>In this section, we'll consider a finite sequence <span class="math">\(s = \langle s_1, \ldots, s_n\rangle\)</span> whose elements <span class="math">\(s_i\)</span> are independent random variables, each uniformly distributed in the interval <span class="math">\((0, 1]\)</span>. These are the partial sums of the sequence <span class="math">\(x_i = s_i - s_{i-1}\)</span>, <span class="math">\(1 \le i \le n\)</span>, where we define <span class="math">\(s_0 = 0\)</span>. Generating <span class="math">\(x\)</span> in this manner ensures it is sum-positive.</p>
      <p>This section focuses on the question: what is the expected value of <span class="math">\(\sigma(x)\)</span>?</p>
      <p>Notice that, if <span class="math">\(i \ne j\)</span>, then <span class="math">\(s_i \ne s_j\)</span> with probability 1. In the context of finding an expected value, we can thus assume without loss of generality that we're only considering sequences <span class="math">\(x\)</span> with distinct partial sums <span class="math">\(s_i\)</span>.</p>
      <p>Property 4 tells us that the order of the elements in <span class="math">\(s\)</span> is all that we need to know in order to find <span class="math">\(\sigma(x)\)</span>, so we'll abstract away the exact values of the <span class="math">\(s_i\)</span> and focus on their relative ordering alone. To this end, let's use the term <span class="math">\(n-\)</span><em>permutation</em> to refer to a bijective map <span class="math">\(\pi:\{1,\ldots,n\}\to\{1,\ldots,n\}\)</span>. Then we can view a sequence <span class="math">\(s\)</span> of distinct elements <span class="math">\(s_i\)</span> as corresponding to a permutation <span class="math">\(\pi\)</span> such that <span class="math">\(s_{\pi(i)}\)</span> is the <span class="math">\(i^\text{th}\)</span> smallest element, where <span class="math">\(1 \le i \le n\)</span>. For example, a strictly increasing <span class="math">\(s\)</span> would correspond to the permutation <span class="math">\(\pi\)</span> with <span class="math">\(\pi(i) = i\)</span>; a strictly decreasing <span class="math">\(s\)</span> would correspond to <span class="math">\(\pi\)</span> with <span class="math">\(\pi(i) = n - i + 1\)</span>.</p>
      <p>In a moment, we'll prove that our random choice of <span class="math">\(s\)</span> corresponds with a uniformly random permutation <span class="math">\(\pi\)</span>. The core intuition is to notice that, for any partial sum sequence <span class="math">\(s = \langle \ldots s_i \ldots s_j \ldots\rangle\)</span>, the new sequence with <span class="math">\(s_i\)</span> and <span class="math">\(s_j\)</span> swapped, <span class="math">\(s&#39; = \langle \ldots s_j \ldots s_i \ldots\rangle\)</span>, is just as likely.</p>
      <p>It will be useful to define a <em>swap of <span class="math">\(i\)</span> and <span class="math">\(j\)</span></em> as a permutation <span class="math">\(\rho\)</span> such that the distinct elements <span class="math">\(i, j\)</span> in its range have <span class="math">\(\rho(i) = j\)</span>, <span class="math">\(\rho(j) = i\)</span>, and for which <span class="math">\(\rho (k) = k\)</span> when <span class="math">\(k \ne i, j\)</span>. Given two <span class="math">\(n-\)</span>permutations <span class="math">\(\pi_1\)</span> and <span class="math">\(\pi_2\)</span>, we'll use the equivalent notations <span class="math">\(\pi_1(\pi_2)\)</span> and <span class="math">\(\pi_1 \circ \pi_2\)</span> to denote the composed permutation <span class="math">\(\pi_3\)</span> defined by <span class="math">\(\pi_3(i) = \pi_1(\pi_2(i))\)</span>.</p>
      <p><strong>Lemma 7</strong>  <em>Suppose we have a probability space over the set of <span class="math">\(n-\)</span>permutations, and that, for any <span class="math">\(n-\)</span>permutation <span class="math">\(\pi\)</span> and swap <span class="math">\(\rho\)</span>, <span class="math">\(\text{Prob}(\pi) = \text{Prob}(\rho(\pi))\)</span>. Then all <span class="math">\(n-\)</span>permutations are equally likely in this space.</em></p>
      <p><strong>Proof</strong>  Let <span class="math">\(\rho_{ij}\)</span> denote the swap of <span class="math">\(i\)</span> and <span class="math">\(j\)</span>. Then the set of swaps <span class="math">\(\{\rho_{ij} | 1\le i &lt; j \le n\}\)</span>, when closed under composition, generates the set of all <span class="math">\(n-\)</span>permutations. One way to see this is by considering the Steinhaus-Johnson-Trotter algorithm, which enumerates all <span class="math">\(n-\)</span>permutations using only swap operations to move from one permutation to the next <span class="citation">(Wikipedia 2015)</span>.</p>
      <p>Since any pair of <span class="math">\(n-\)</span>permutations <span class="math">\(\pi_1\)</span> and <span class="math">\(\pi_2\)</span> are a finite pair of swaps apart, they must have the same probability. More formally, there must exist a finite sequence of swaps <span class="math">\(\rho_1, \ldots, \rho_k\)</span> so that <span class="math">\(\pi_1 = \rho_1 \circ \ldots \circ \rho_k \circ \pi_2\)</span>. Then <span class="math">\[\text{Prob}(\pi_2) = \text{Prob}(\rho_k \circ \pi_2)
                           = \ldots
                           = \text{Prob}(\rho_1 \circ \ldots \circ \rho_k \circ \pi_2)
                           = \text{Prob}(\pi_1).\]</span> <span class="math">\(\Box\)</span></p>
      <p>The proof only depended on two key facts about the probability space on sequences <span class="math">\(s\)</span>:</p>
      <ol style="list-style-type: decimal">
      <li>that elements <span class="math">\(s_i\)</span> are distinct with probability 1, and</li>
      <li>that permutation elements separated by a swap have the same probability.</li>
      </ol>
      <p>In other words, lemma 7 applies to any sequence <span class="math">\(s_i\)</span> whose elements are chosen independently using the same probability distribution in which all individual elements have probability zero. Choosing <span class="math">\(s_i\)</span> uniformly from <span class="math">\((0, 1]\)</span> is just one example of a probability space that meets these conditions.</p>
      <p>Armed with this characterization of uniformly random permutations, we're ready to find the expected value of <span class="math">\(\sigma(x)\)</span>. To do so, it will be useful to define the <span class="math">\(n^\text{th}\)</span> <em>harmonic number</em> <span class="math">\(H_n\)</span> as <span class="math">\(\sum_{i=1}^n1/i\)</span>.</p>
      <p><strong>Property 8</strong>  <em>Suppose that the random sequence <span class="math">\(s\)</span> is determined by independently choosing each <span class="math">\(s_i\)</span> uniformly from <span class="math">\((0, 1]\)</span> for each <span class="math">\(i\)</span> with <span class="math">\(1 \le i \le n\)</span>; suppose also that <span class="math">\(x_i = s_i - s_{i-1}\)</span>, where <span class="math">\(1 \le i \le n\)</span> and <span class="math">\(s_0 = 0\)</span>. Then the expected value of <span class="math">\(\sigma(x)\)</span> is <span class="math">\(H_n\)</span>.</em></p>
      <p><strong>Proof </strong>  As noted above, we can assume without loss of generality that <span class="math">\(s_i \ne s_j\)</span> for <span class="math">\(i\ne j\)</span>; this is excluding a zero-probability case, so it doesn't affect the expected value of <span class="math">\(\sigma(x)\)</span>.</p>
      <p>Let <span class="math">\(\pi\)</span> be the <span class="math">\(n-\)</span>permutation such that <span class="math">\(s_{\pi(i)}\)</span> is the <span class="math">\(i^\text{th}\)</span> smallest partial sum for <span class="math">\(1 \le i \le n\)</span>. Note that <span class="math">\(s_{\pi(i)} &lt; s_{\pi(j)}\)</span> iff <span class="math">\(i &lt; j\)</span>.</p>
      <p>We can use the set <span class="math">\(S(x)\)</span> to determine <span class="math">\(\sigma(x)\)</span>. Notice that <span class="math">\(s_{\pi(k)} \in S(x)\)</span> iff <span class="math">\(\pi(i) &lt; \pi(k)\)</span> for all <span class="math">\(i &lt; k\)</span>; call this event <span class="math">\(e_k\)</span>. This event is entirely determined by the order of <span class="math">\(\pi(1), \ldots, \pi(k)\)</span>, of which there are <span class="math">\(k!\)</span> equally likely possibilities. Exactly <span class="math">\(1/k\)</span> of those orderings have <span class="math">\(\pi(k)\)</span> as the largest element. Thus, <span class="math">\(\text{Prob}(e_k) = 1/k\)</span>.</p>
      <p>So the expected value of <span class="math">\(\sigma(x)\)</span> is <span class="math">\[\sum_{k=1}^n \text{Prob}(e_k) = \sum_{k=1}^n1/k = H_n,\]</span> using the linearity of the expected value. This completes the proof. <span class="math">\(\Box\)</span></p>
      <p>Now we're ready to consider a more interesting random sequence — one where each <span class="math">\(x_i\)</span> is chosen uniformly from <span class="math">\([-1, 1]\)</span>. As before, the goal is to find the expected value of <span class="math">\(\sigma(x)\)</span>.</p>
      <p>The following lemma is the key. We'll need to introduce notation for a <em>double factorial</em>, written <span class="math">\(n!!\)</span>, which is defined as <span class="math">\[n!! = n(n-2)(n-4)\cdots(1 \text{ or } 2).\]</span> In other words, <span class="math">\(n!!\)</span> is the product of all the integers in <span class="math">\([1, n]\)</span> with the same parity — being even or odd — as <span class="math">\(n\)</span>.</p>
      <p><strong>Lemma 9</strong>  <em>Suppose that the random sequence <span class="math">\(x\)</span> is determined by independently choosing each <span class="math">\(x_i\)</span> uniformly from <span class="math">\([-1, 1]\)</span> for each <span class="math">\(i\)</span> with <span class="math">\(1\le i\le n\)</span> and that <span class="math">\(s_k = \sum_{i=1}^kx_i\)</span>. Then <span class="math">\[\text{Pr}(s_k&gt;0\,\forall\,k:1\le k\le n) = \frac{(2n-1)!!}{(2n)!!}.\]</span></em></p>
      <p>The event in that last expression could be alternatively stated as &quot;<span class="math">\(x\)</span> is sum-positive.&quot; The proof of this lemma is involved, so we'll defer it until after we've seen how it can be used to prove the following property which answers our key question about <span class="math">\(\sigma(x)\)</span>.</p>
      <p><strong>Property 10</strong>  <em>Suppose that the random sequence <span class="math">\(x\)</span> is determined by independently choosing each <span class="math">\(x_i\)</span> uniformly from <span class="math">\([-1, 1]\)</span> for each <span class="math">\(i\)</span> with <span class="math">\(1\le i\le n\)</span>. Then the expected value of <span class="math">\(\sigma(x)\)</span> is <span class="math">\[n\frac{(2n-1)!!}{(2n)!!}.\]</span></em></p>
      <p>Before proving this, it may be interesting to shed more light on the quantity <span class="math">\(E_n = n(2n-1)!!/(2n)!!\)</span>. For example, it may not be obvious at first glance if <span class="math">\(E_n\)</span> increases or decreases as <span class="math">\(n\to\infty\)</span>.</p>
      <p>Here's a table of the first few values:</p>
      <table>
      <thead>
      <tr class="header">
      <th align="left"><span class="math">\(n\)</span></th>
      <th align="left"></th>
      <th align="left">1</th>
      <th align="left">2</th>
      <th align="left">3</th>
      <th align="left">4</th>
      <th align="left">5</th>
      <th align="left">6</th>
      <th align="left">7</th>
      <th align="left">8</th>
      </tr>
      </thead>
      <tbody>
      <tr class="odd">
      <td align="left"><span class="math">\(E_n\;\;\)</span></td>
      <td align="left"></td>
      <td align="left"><span class="math">\(\frac{1}{2}\vphantom{\bigg|}\)</span></td>
      <td align="left"><span class="math">\(\frac{3}{4}\)</span></td>
      <td align="left"><span class="math">\(\frac{15}{16}\)</span></td>
      <td align="left"><span class="math">\(\frac{35}{32}\)</span></td>
      <td align="left"><span class="math">\(\frac{315}{256}\)</span></td>
      <td align="left"><span class="math">\(\frac{693}{512}\)</span></td>
      <td align="left"><span class="math">\(\frac{3003}{2048}\)</span></td>
      <td align="left"><span class="math">\(\frac{6435}{4096}\)</span></td>
      </tr>
      <tr class="even">
      <td align="left"><span class="math">\(\approx\)</span></td>
      <td align="left"></td>
      <td align="left">0.50<span class="math">\(\vphantom{ }\quad\)</span></td>
      <td align="left">0.75<span class="math">\(\quad\)</span></td>
      <td align="left">0.93<span class="math">\(\quad\)</span></td>
      <td align="left">1.09<span class="math">\(\quad\)</span></td>
      <td align="left">1.23<span class="math">\(\quad\)</span></td>
      <td align="left">1.35<span class="math">\(\quad\)</span></td>
      <td align="left">1.46<span class="math">\(\quad\)</span></td>
      <td align="left">1.57</td>
      </tr>
      </tbody>
      </table>
      <p>The ratio between consecutive values is, for <span class="math">\(n &gt; 1\)</span>, <span class="math">\[\frac{E_n}{E_{n-1}} = \frac{n}{n-1}\frac{2n-1}{2n}=\frac{n-1/2}{n-1}=1+\frac{1}{2n-2} &gt; 1,\]</span> so that they are indeed strictly increasing. In fact, since <span class="math">\(\sum_{1 &lt; k \le n} \frac{1}{2k-2}\to\infty\)</span> as <span class="math">\(n\to\infty\)</span>, we also have <span class="math">\(E_n = \frac{1}{2}\prod_{1 &lt; k \le n}\left( 1 + \frac{1}{2k-2}\right) \to \infty\)</span> as <span class="math">\(n\to\infty\)</span>.</p>
      <p>Let's prove property 10, assuming for now that lemma 9 is true.</p>
      <p><strong>Proof of property 10</strong>  For <span class="math">\(0 \le k &lt; n\)</span>, let <span class="math">\(\rho_k(x)\)</span> denote the cyclic shift <span class="math">\(\langle x_{k+1}, \ldots, x_n, x_1, \ldots, x_k\rangle\)</span> of <span class="math">\(x = \langle x_1, \ldots, x_n\rangle\)</span>. Thus <span class="math">\(\rho_0\)</span> is the identity, and <span class="math">\(x_2\)</span> is the first element of <span class="math">\(\rho_1(x)\)</span>; we can think of <span class="math">\(\rho_k\)</span> as being a cycle-by-<span class="math">\(k\)</span> mapping.</p>
      <p>For random event <span class="math">\(A\)</span>, let <span class="math">\([A]\)</span> denote the function with value 1 if <span class="math">\(A\)</span> is true, and 0 otherwise. Then we can write <span class="math">\[\sigma(x) = \sum_{k=0}^{n-1}[\rho_k(x)\text{ is sum-positive}].\]</span> Let <span class="math">\(E\,X\)</span> denote the expected value of a random variable <span class="math">\(X\)</span>. Then <span class="math">\[E\,\sigma(x) = \sum_{k=0}^{n-1}E\,[\rho_k(x)\text{ is sum-positive}]
                     = \sum_{k=0}^{n-1}\text{Pr}(\rho_k(x)\text{ is sum-positive}).\]</span> Since the elements of <span class="math">\(x\)</span> are chosen independently, and with an identical distribution, we also have <span class="math">\[\text{Pr}(\rho_i(x)\text{ is sum-positive}) =
        \text{Pr}(\rho_j(x)\text{ is sum-positive}) \quad \forall i,j.\]</span> In other words, <span class="math">\[E\,\sigma(x) = n \, \text{Pr}(x\text{ is sum-positive})
                     = n \, \frac{(2n-1)!!}{(2n)!!},\]</span> using lemma 9 for the final equation. <span class="math">\(\Box\)</span></p>
      <p>Now we're ready to dive into the proof of lemma 9.</p>
      <p><strong>Proof of lemma 9</strong>  Our goal is to study the event <span class="math">\(e_n = (s_k &gt; 0 \,\forall\, k:1\le k \le n)\)</span>. To this end, we'll study the distribution of the random variable <span class="math">\((s_k | e_{k-1})\)</span>; that is, the value of <span class="math">\(s_k\)</span> given that <span class="math">\(s_j &gt; 0\)</span> for <span class="math">\(j &lt; k\)</span>. Let <span class="math">\(g_k\)</span> be the probability density function of <span class="math">\((s_k | e_{k-1})\)</span>, characterized by <span class="math">\(\text{Pr}(s_k \in A \,|\, e_{k-1}) = \int_A g_k(x)dx\)</span>. The first few <span class="math">\(g_k\)</span> functions are illustrated below.</p>
      <div class="figure">
      <img src="images/g_k_outlines.png" alt="Outlines of the probability density functions g_k." />
      <p class="caption"><em>Outlines of the probability density functions <span class="math">\(g_k\)</span>.</em></p>
      </div>
      <p>The first function, <span class="math">\(g_1\)</span>, is entirely determined by the distribution of <span class="math">\(x_1\)</span> itself; that is, <span class="math">\(g_1 = \frac{1}{2}[-1 \le x \le 1]\)</span>. For <span class="math">\(k &gt; 1\)</span>, we can recursively compute <span class="math">\(g_k\)</span> by considering the probability that <span class="math">\(s_k=w\)</span> given event <span class="math">\(e_{k-1}\)</span>. In event <span class="math">\(e_{k-1}\)</span>, the density function of <span class="math">\(s_{k-1}\)</span> is simply the value of <span class="math">\(g_{k-1}(x)\)</span> restricted to <span class="math">\(x &gt; 0\)</span> and normalized to integrate to 1. Let <span class="math">\(q_k = \int_{x &gt; 0} g_k(x) dx\)</span>, and we can express the density function of <span class="math">\((s_{k-1}|e_{k-1})\)</span> as <span class="math">\(g_{k-1}(x)[x&gt;0]/q_{k-1}\)</span>.</p>
      <p>From here, the density function value for <span class="math">\(s_k=w\)</span> given <span class="math">\(e_{k-1}\)</span> is intuitively the sum of probabilities <span class="math">\(\text{Pr}(s_{k-1}=w_1 | e_{k-1}) \text{Pr}(x_k=w_2)\)</span> across all <span class="math">\(w_1, w_2\)</span> pairs with <span class="math">\(w_1 + w_2 = w\)</span>. More formally, we convolute the density functions of <span class="math">\(x_k\)</span> and <span class="math">\((s_{k-1} | e_{k-1})\)</span> to arrive at <span class="math">\[g_k(w) = \frac{1}{2q_{k-1}}\int_{w-1}^{w+1}g_{k-1}(x)[x&gt;0]dx.\]</span></p>
      <p>By the structure of this definition, each <span class="math">\(g_k\)</span> with <span class="math">\(k &gt; 1\)</span> is continuous everywhere and linear on each interval between integers <span class="math">\([n, n+1]\)</span>, <span class="math">\(n\in\mathbb{Z}\)</span>.</p>
      <p>It's also the case that, for <span class="math">\(k &gt; 1\)</span>, <span class="math">\(g_k(w) = 0\)</span> when <span class="math">\(w \le -1\)</span> and when <span class="math">\(w \ge k\)</span>, which can be verified inductively. This means we can consider each function as an element of a vector space with basis elements <span class="math">\[b_w(x) = \max (1-|x-w|, 0).\]</span> This is essentially a triangle with base width 2 and height and area 1.</p>
      <hr />
      <p>(TODO add code that checks this; consider the case <span class="math">\(x_i\in[-1, 1]\)</span> but don't spend too much time on it if it's tricky)</p>
      <p>(TODO show that lemmas 1 and 2 are corollaries of property 5)</p>
      <div class="references">
      <h1 id="references" class="unnumbered">References</h1>
      <p>Knuth, Donald E., Oren Patashnik, and Ronald L. Graham. 1998. <em>Concrete Mathematics: A Foundation for Computer Science</em>. addison-wesley.</p>
      <p>Raney, George. 1960. “Functional Composition Patterns and Power Series Reversion.” <em>Transactions of the American Mathematical Society</em> 94: 441–51.</p>
      <p>Wikipedia. 2015. “Steinhaus-Johnson-Trotter Algorithm — Wikipedia, the Free Encyclopedia.” <a href="http://en.wikipedia.org/wiki/Steinhaus-Johnson-Trotter_algorithm" class="uri">http://en.wikipedia.org/wiki/Steinhaus-Johnson-Trotter_algorithm</a>.</p>
      </div>
    </div>
  </body>
</html>

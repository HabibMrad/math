<!doctype html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>CS 229 Homework</title>
    <script src='/Users/tylerneylon/Dropbox/Documents/code/MathJax/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
    <link rel="stylesheet" href="tufte-edited.css"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
  </head>
  <body>
    <p style="display:none">\(\newcommand{\latexonlyrule}[2]{}\)</p>
    <div class="main">
      <div class="title">CS 229 Homework</div>
      <div class="author">Tyler Neylon</div>
      <div class="date">345.2016</div>
<p>These are solutions to the most recent problems posted for Stanford’s CS 229 course, as of June 2016. I’m not sure if this course re-uses old problems, but please don’t copy the answers if so. This document is also available as a <a href="http://tylerneylon.com/notes/cs229/cs229hw.pdf">pdf</a>.</p>
<h1 id="problem-set-1"><span class="header-section-number">1</span> Problem set 1</h1>
<h2 id="logistic-regression"><span class="header-section-number">1.1</span> Logistic regression</h2>
<h3 id="part-a"><span class="header-section-number">1.1.1</span> Part (a)</h3>
<p>The problem is to compute the Hessian matrix <span class="math inline">\(H\)</span> for the function</p>
<p><span class="math display">\[J({\theta}) = -\frac{1}{m}\sum_{i=1}^m\log(g(y{^{(i)}}x{^{(i)}})),\]</span></p>
<p>where <span class="math inline">\(g(z)\)</span> is the logistic function, and to show that <span class="math inline">\(H\)</span> is positive semi-definite; specifically, that <span class="math inline">\(z^THz\ge 0\)</span> for any vector <span class="math inline">\(z.\)</span></p>
<p>We’ll use the fact that <span class="math inline">\(g&#39;(z) = g(z)(1-g(z)).\)</span> We’ll also note that since all relevant operations are linear, it will suffice to ignore the summation over <span class="math inline">\(i\)</span> in the definition of <span class="math inline">\(J.\)</span> I’ll use the notation <span class="math inline">\(\partial_j\)</span> for <span class="math inline">\(\frac{\partial}{\partial{\theta}_j},\)</span> and introduce <span class="math inline">\(t\)</span> for <span class="math inline">\(y{\theta}^Tx.\)</span> Then</p>
<p><span class="math display">\[-\partial_j(mJ) = \frac{g(t)(1-g(t))}{g(t)}x_jy = x_jy(1-g(t)).\]</span></p>
<p>Next</p>
<p><span class="math display">\[-\partial_k\partial_j(mJ) = x_jy\big(-g(t)(1-g(t))\big)x_ky,\]</span></p>
<p>so that</p>
<p><span class="math display">\[\partial_{jk}(mJ) = x_jx_ky^2\alpha,\]</span></p>
<p>where <span class="math inline">\(\alpha = g(t)(1-g(t)) &gt; 0.\)</span></p>
<p>Thus we can use repeated-index summation notation to arrive at</p>
<p><span class="math display">\[z^THz = z_ih_{ij}z_j = (\alpha y^2)(z_ix_ix_jz_j)
        = (\alpha y^2)(x^Tz)^2 \ge 0.\]</span></p>
<p>This completes this part of the problem.</p>
<h3 id="part-b"><span class="header-section-number">1.1.2</span> Part (b)</h3>
<p>Here is a matlab script to solve this part of the problem:</p>
<pre><code>% problem1_1b.m
%
% Run Newton&#39;s method on a given cost function for a logistic
% regression setup.
%

printf(&#39;Running problem1_1b.m\n&#39;);

% Be able to compute J.
function val = J(Z, theta)
  [m, _] = size(Z);
  g      = 1 ./ (1 + exp(Z * theta));
  val    = -sum(log(g)) / m;
end

% Setup.
X      = load(&#39;logistic_x.txt&#39;);
[m, n] = size(X);
X      = [ones(m, 1) X];
Y      = load(&#39;logistic_y.txt&#39;);
Z      = diag(Y) * X;

% Initialize the parameters to learn.
old_theta =  ones(n + 1, 1);
theta     = zeros(n + 1, 1);
i         = 1;  % i = iteration number.

% Perform Newton&#39;s method.
while norm(old_theta - theta) &gt; 1e-5
  printf(&#39;J = %g\n&#39;, J(Z, theta));
  printf(&#39;theta:\n&#39;);
  disp(theta);
  printf(&#39;Running iteration %d\n&#39;, i);

  g         = 1 ./ (1 + exp(Z * theta));
  f         = (1 - g);
  alpha     = f .* g;
  A         = diag(alpha);
  H         = Z&#39; * A * Z / m;
  nabla     = Z&#39; * f / m;
  old_theta = theta;
  theta     = theta - inv(H) *  nabla;

  i++;
end

% Show and save output.
printf(&#39;Final theta:\n&#39;);
disp(theta);
save(&#39;theta.mat&#39;, &#39;theta&#39;);</code></pre>
<p>Because I have copious free time, I also wrote a Python version. Also because I’m learning numpy and would prefer to consistently use a language that I know can produce decent-looking graphs. Here is the Python script:</p>
<pre><code>#!/usr/bin/env python

import numpy as np
from numpy import linalg as la


# Define the J function.
def J(Z, theta):
  m, _ = Z.shape
  g    = 1 / (1 + np.exp(Z.dot(theta)))
  return -sum(np.log(g)) / m

# Load data.
X    = np.loadtxt(&#39;logistic_x.txt&#39;)
m, n = X.shape
X    = np.insert(X, 0, 1, axis=1)  # Prefix an all-1 column.
Y    = np.loadtxt(&#39;logistic_y.txt&#39;)
Z    = np.diag(Y).dot(X);

# Initialize the learning parameters.
old_theta = np.ones((n + 1,))
theta     = np.zeros((n + 1,))
i         = 1

# Perform Newton&#39;s method.
while np.linalg.norm(old_theta - theta) &gt; 1e-5:

  # Print progress.
  print(&#39;J = {}&#39;.format(J(Z, theta)))
  print(&#39;theta = {}&#39;.format(theta))
  print(&#39;Running iteration {}&#39;.format(i))

  # Update theta.
  g         = 1 / (1 + np.exp(Z.dot(theta)))
  f         = 1 - g
  alpha     = (f * g).flatten()
  H         = (Z.T * alpha).dot(Z) / m
  nabla     = Z.T.dot(f) / m
  old_theta = theta
  theta     = theta - la.inv(H).dot(nabla)

  # Update i = the iteration counter.
  i += 1

# Print and save the final value.
print(&#39;Final theta = {}&#39;.format(theta))
np.savetxt(&#39;theta.txt&#39;, theta)</code></pre>
<p>The final value of <span class="math inline">\({\theta}\)</span> that I arrived at is</p>
<p><span class="math display">\[{\theta}= (2.62051, -0.76037, -1.17195).\]</span></p>
<p>The first value <span class="math inline">\({\theta}_0\)</span> represents the constant term, so that the final model is given by</p>
<p><span class="math display">\[y = g(2.62 - 0.76x_1 - 1.17x_2).\]</span></p>
<h3 id="part-c"><span class="header-section-number">1.1.3</span> Part (c)</h3>
<div class="figure">
<p class="caption">The data points given for problem 1.1 along with the decision boundary learned by logistic regression as executed by Newton’s method.</p>
<img src="images/pr1_1c.png" alt="The data points given for problem 1.1 along with the decision boundary learned by logistic regression as executed by Newton’s method." />
</div>
<h2 id="poisson-regression-and-the-exponential-family"><span class="header-section-number">1.2</span> Poisson regression and the exponential family</h2>
<h3 id="part-a-1"><span class="header-section-number">1.2.1</span> Part (a)</h3>
<p>Write the Poisson distribution as an exponential family:</p>
<p><span class="math display">\[p(y;\eta) = b(y)\exp\big(\eta^T T(y) - a(\eta)\big),\]</span></p>
<p>where</p>
<p><span class="math display">\[p(y;\lambda) = \frac{e^{-\lambda}\lambda^y}{y!}.\]</span></p>
<p>This can be done via</p>
<p><span class="math display">\[\begin{array}{rcl}
\eta &amp; = &amp; \log(\lambda), \\
a(\eta) &amp; = &amp; e^\eta = \lambda, \\
b(y) &amp; = &amp; 1/y!, \text{ and} \\
T(y) &amp; = &amp; y.
\end{array}\]</span></p>
<h3 id="part-b-1"><span class="header-section-number">1.2.2</span> Part (b)</h3>
<p>As is usual with generalized linear models, we’ll let <span class="math inline">\(\eta = {\theta}^Tx.\)</span> The canonical response function is then given by</p>
<p><span class="math display">\[g(\eta) = E[y;\eta] = \lambda = e^\eta = e^{{\theta}^Tx}.\]</span></p>
<h3 id="part-c-1"><span class="header-section-number">1.2.3</span> Part (c)</h3>
<p>Based on the last part, I’ll define the hypothesis function <span class="math inline">\(h\)</span> via <span class="math inline">\(h(x) = e^{{\theta}^Tx}.\)</span></p>
<p>For a single data point <span class="math inline">\((x, y),\)</span> let <span class="math inline">\(\ell({\theta}) = \log(p(y|x)) =\)</span> <span class="math inline">\(\log(\frac{1}{y!}) + (y{\theta}^T x-e^{{\theta}^Tx}).\)</span> Then</p>
<p><span class="math display">\[\frac{\partial}{\partial{\theta}_j}\ell({\theta}) = yx_j - x_je^{{\theta}^Tx}
= x_j(y-e^{{\theta}^Tx}).\]</span></p>
<p>So stochastic gradient ascent for a single point <span class="math inline">\((x, y)\)</span> would use the update rule</p>
<p><span class="math display">\[{\theta}:= {\theta}+ \alpha x(y - h(x)).\]</span></p>
<h3 id="part-d"><span class="header-section-number">1.2.4</span> Part (d)</h3>
<p>In section 1.10 of my notes — the section on generalized linear models — I derived the update rule:</p>
<p><span class="math display">\[{\theta}:= {\theta}+ \alpha\big(T(y)-a&#39;({\theta}^Tx)\big)x.\]</span></p>
<p>The missing piece is to proof that <span class="math inline">\(h(x) = E[y] = a&#39;(\eta),\)</span> which we’ll do next. We’ll work in the context of <span class="math inline">\(T(y)=y,\)</span> as given by the problem statement. Notice that, for any <span class="math inline">\(\eta,\)</span></p>
<p><span class="math display">\[\int p(y)dy = \int b(y)\exp(\eta^Ty - a(\eta))dy = 1.\]</span></p>
<p>Since this identity is true for all values of <span class="math inline">\(\eta,\)</span> we can take <span class="math inline">\(\frac{\partial}{\partial\eta}\)</span> of it to arrive at the value 0:</p>
<p><span class="math display">\[\begin{array}{rcl}
 0 &amp; = &amp; \frac{\partial}{\partial\eta}\int p(y)dy \\
   &amp; = &amp; \int \frac{\partial}{\partial\eta} b(y)\exp(\eta^Ty - a(\eta))dy \\
   &amp; = &amp; \int b(y)(y - a&#39;(\eta))\exp(\eta^Ty - a(\eta)) dy \\
   &amp; = &amp; \int y p(y)dy - a&#39;(\eta)\int p(y)dy \\
   &amp; = &amp; E[y] - a&#39;(\eta).
\end{array}\]</span></p>
<p>Thus we can conclude that <span class="math inline">\(E[y] = a&#39;(\eta) = a&#39;({\theta}^Tx),\)</span> which completes the solution.</p>
<h2 id="gaussian-discriminant-analysis"><span class="header-section-number">1.3</span> Gaussian discriminant analysis</h2>
<h3 id="part-a-2"><span class="header-section-number">1.3.1</span> Part (a)</h3>
<p>This problem is to show that a two-class GDA solution effectively provides a model that takes the form of a logistic function, similar to logistic regression. This is something I already did in section 2.1 of <a href="http://tylerneylon.com/notes/cs229/cs229.html">my notes</a>.</p>
<h3 id="parts-b-and-c"><span class="header-section-number">1.3.2</span> Parts (b) and (c)</h3>
<p>These parts ask to derive the maximum likelihood estimates of <span class="math inline">\(\phi,\)</span> <span class="math inline">\(\mu_0,\)</span> <span class="math inline">\(\mu_1,\)</span> and <span class="math inline">\(\Sigma\)</span> for GDA. Part (b) is a special case of part (c), so I’ll just do part (c).</p>
<p><strong>Some lemmas</strong></p>
<p>It will be useful to know a couple vector- and matrix-oriented calculus facts which I’ll briefly derive here.</p>
<p>First I’ll show that, given column vectors <span class="math inline">\(a\)</span> and <span class="math inline">\(b,\)</span> and symmetric matrix <span class="math inline">\(C,\)</span></p>
<p><span class="math display">\[\nabla_b [ (a-b)^T C (a-b) ] = -2C(a-b).\qquad(1)\]</span></p>
<p>We can derive this by looking at the <span class="math inline">\(k^\text{th}\)</span> coordinate of the gradient. Let <span class="math inline">\(x = (a-b)^T C (a-b).\)</span> Then, using repeated index summation notation,</p>
<p><span class="math display">\[\begin{array}{crcl}
&amp; x &amp; = &amp; (a_i - b_i)c_{ij}(a_j-b_j) \\
\Rightarrow &amp; [\nabla_b]_k x &amp; = &amp; -c_{kj}(a_j - b_j) - (a_i - b_i)c_{ik} \\
 &amp; &amp; = &amp; -2C(a-b). \\
\end{array}\]</span></p>
<p>Next I’ll show that</p>
<p><span class="math display">\[\frac{\partial}{\partial C}(a-b)^T C (a-b) = (a-b)(a-b)^T.\qquad(2)\]</span></p>
<p>This follows since</p>
<p><span class="math display">\[(a-b)^T C (a-b) = (a_i - b_i) c_{ij} (a_j - b_j),\]</span></p>
<p>so that</p>
<p><span class="math display">\[\frac{\partial}{\partial c_{ij}} (a-b)^T C (a-b)
= (a_i - b_i)(a_j - b_j).\]</span></p>
<p>In other words, the <span class="math inline">\(ij^\text{th}\)</span> entry of the matrix derivative is exactly the <span class="math inline">\(ij^\text{th}\)</span> entry of the matrix <span class="math inline">\((a-b)(a-b)^T.\)</span></p>
<p>Finally, I’ll mention that, when a matrix <span class="math inline">\(A\)</span> is invertibe,</p>
<p><span class="math display">\[\frac{d}{dA} |A| = |A|\,A^{-T}.\qquad(3)\]</span></p>
<p>This can be seen by considering that the <span class="math inline">\(ij^\text{th}\)</span> entry of <span class="math inline">\(A^{-1}\)</span> can be written as</p>
<p><span class="math display">\[(A^{-1})_{ij} = ((-1)^{i+j}M_{ji})/|A|,\qquad(4)\]</span></p>
<p>where <span class="math inline">\(M_{ij}\)</span> denotes the determinant of the minor of <span class="math inline">\(A\)</span> achieved by removing the <span class="math inline">\(i^\text{th}\)</span> row and <span class="math inline">\(j^\text{th}\)</span> column. Next, consider the expression for <span class="math inline">\(A\)</span> as a sum of products <span class="math inline">\(\sigma(\pi)\prod a_{i\pi(i)}\)</span> over all permutations <span class="math inline">\(\pi:[n]\to[n]\)</span> where <span class="math inline">\(\sigma(\pi)\)</span> is the sign of permutation <span class="math inline">\(\pi\)</span> (<a href="https://en.wikipedia.org/wiki/Determinant#n_.C3.97_n_matrices">reference</a>). Based on that definition of a determinant, it can be derived that</p>
<p><span class="math display">\[\frac{\partial}{\partial a_{ij}}|A| = (-1)^{i+j}M_{ij}.\]</span></p>
<p>Combine this last result with (4) to arrive at (3).</p>
<p><strong>The solution</strong></p>
<p>We’re now ready to derive the equations for the GDA parameters based on maximum likelihood estimation.</p>
<p>The log likelihood function is</p>
<p><span class="math display">\[\ell = \sum_i \log(p(x|y)) + \log(p(y)).\]</span></p>
<p><span class="math inline">\(\phi\)</span></p>
<p>In this section I’ll start to use the notation <span class="math inline">\([\textsf{Pred}(x)]\)</span> for the indicator function of a boolean predicate <span class="math inline">\(\textsf{Pred}(x):\)</span></p>
<p><span class="math display">\[[\textsf{Pred}(x)] := \begin{cases}
1 &amp; \text{if }\textsf{Pred}(x)\text{ is true, and} \\
0 &amp; \text{otherwise.} \\
\end{cases}\]</span></p>
<p>This is the notation that Knuth uses, and I prefer it to Ng’s notation <span class="math inline">\(1\{\textsf{Pred}(x)\}.\)</span></p>
<p>Treating <span class="math inline">\(p(y)\)</span> as <span class="math inline">\(\phi^y(1-\phi)^{1-y},\)</span> set <span class="math inline">\({\frac{\partial}{\partial \phi}}\)</span> of <span class="math inline">\(\ell\)</span> to 0; the result is</p>
<p><span class="math display">\[\sum_i{\frac{\partial}{\partial \phi}}\big(y\log\phi + (1-y)\log(1-\phi)\big)
= \sum_i \frac{y}{\phi} - \frac{1-y}{1-\phi} = 0\]</span></p>
<p><span class="math display">\[\Rightarrow\quad \sum_i y(1-\phi) - (1-y)\phi = 0\]</span></p>
<p><span class="math display">\[\Rightarrow\quad m_1 - m_1\phi = m_0\phi,\]</span></p>
<p>where <span class="math inline">\(m_j = \sum_i [y{^{(i)}}= j],\)</span> and I’m treating the possible <span class="math inline">\(y\)</span> values as 0 or 1. Then</p>
<p><span class="math display">\[m_1 = \phi(m_0 + m_1) \;\Rightarrow\; \phi = \frac{m_1}{m},\]</span></p>
<p>using that <span class="math inline">\(m = m_0 + m_1.\)</span></p>
<p><span class="math inline">\(\mu_j\)</span></p>
<p><span class="math display">\[{\frac{\partial}{\partial \mu_j}}\ell = {\frac{\partial}{\partial \mu_j}}\sum_{y=j}-\frac{1}{2}(x-\mu_j)^T{\Sigma^{-1}}(x-\mu_j)\]</span></p>
<p>We can use (1) to see that this is the same as</p>
<p><span class="math display">\[\sum_{y=j} {\Sigma^{-1}}(x-\mu_j).\]</span></p>
<p>Setting <span class="math inline">\({\frac{\partial}{\partial \mu_j}}\ell = 0,\)</span> and noticing that <span class="math inline">\({\Sigma^{-1}}\)</span> must be nonsingular as it’s an inverse, we get</p>
<p><span class="math display">\[\sum_{y=j} x = \sum_{y=j} \mu_j,\]</span></p>
<p>resulting in</p>
<p><span class="math display">\[
\sum_{y=j} x = m_j \mu_j \quad \Rightarrow \quad
\mu_j = \frac{1}{m_j}\sum_{y=j}x
.\]</span></p>
<p><span class="math inline">\(\Sigma\)</span></p>
<p>To get an equation for <span class="math inline">\(\Sigma,\)</span> we’ll actually maximize <span class="math inline">\(\ell\)</span> with respect to its inverse <span class="math inline">\({\Sigma^{-1}}.\)</span> This works because there is a bijection between all possible values of <span class="math inline">\({\Sigma^{-1}}\)</span> and of <span class="math inline">\(\Sigma\)</span> under the constraint that <span class="math inline">\(\Sigma\)</span> is invertible, which is required for GDA to make sense. Thus the value of <span class="math inline">\({\Sigma^{-1}}\)</span> which maximizes <span class="math inline">\(\ell\)</span> uniquely identifies the value of <span class="math inline">\(\Sigma\)</span> which maximizes <span class="math inline">\(\ell.\)</span></p>
<p><span class="math display">\[{\frac{\partial}{\partial {\Sigma^{-1}}}}\ell = \sum_i{\frac{\partial}{\partial {\Sigma^{-1}}}}\left(C + \frac{1}{2}\log |{\Sigma^{-1}}| -
\frac{1}{2}(x-\mu_y)^T{\Sigma^{-1}}(x-\mu_y)\right).\]</span></p>
<p>Use (2) to see that this is the same as</p>
<p><span class="math display">\[\sum_i \frac{|{\Sigma^{-1}}|\Sigma^T}{|{\Sigma^{-1}}|} - \frac{1}{2}(x-\mu_y)(x-\mu_y)^T.\]</span></p>
<p>Set this value to 0 to arrive at</p>
<p><span class="math display">\[\sum_i \Sigma^T = \sum_i (x-\mu_y)(x-\mu_y)^T
\quad\Rightarrow\quad
\Sigma^T = \frac{1}{m}\sum_i (x-\mu_y)(x-\mu_y)^T.\]</span></p>
<p>Since the expression on the right must give a symmetric matrix, this same expression also gives the value for <span class="math inline">\(\Sigma\)</span> itself.</p>
<h2 id="linear-invariance-of-optimization-algorithms"><span class="header-section-number">1.4</span> Linear invariance of optimization algorithms</h2>
<h3 id="part-a-3"><span class="header-section-number">1.4.1</span> Part (a)</h3>
<p>This problem is to show that Newton’s method is invariant to linear reparametrizations.</p>
<p>Specifically, suppose <span class="math inline">\(x^{(0)} = z^{(0)} = 0,\)</span> that matrix <span class="math inline">\(A\)</span> is invertible, and that <span class="math inline">\(g(z) = f(Az).\)</span> Our goal is to show that if the sequence <span class="math inline">\(x^{(1)}, x^{(2)}, \ldots\)</span> results from Newton’s method applied to <span class="math inline">\(f\)</span>, then the corresponding sequence <span class="math inline">\(z^{(1)}, z^{(2)}, \ldots\)</span> resulting from Newton’s method applied to <span class="math inline">\(g\)</span> obeys the equation <span class="math inline">\(x^{(i)} = Az^{(i)}\)</span> for all <span class="math inline">\(i,\)</span> so that the two versions of Newton’s method are in a sense doing the exact same work. We’ll think of <span class="math inline">\(f\)</span> consistently as a function of <span class="math inline">\(x,\)</span> and <span class="math inline">\(g\)</span> as a function of <span class="math inline">\(z.\)</span></p>
<p>Start with</p>
<p><span class="math display">\[\big[\nabla_z g\big]_i = {\frac{\partial f}{\partial z_i}} = {\frac{\partial f}{\partial x_j}}{\frac{\partial x_j}{\partial z_i}}
= {\frac{\partial f}{\partial x_j}}a_{ji},\]</span></p>
<p>from which it follows that</p>
<p><span class="math display">\[\nabla g = A^T\nabla f.\]</span></p>
<p>Next, introduce the variables <span class="math inline">\(H\)</span> as the Hessian of <span class="math inline">\(f,\)</span> and <span class="math inline">\(P\)</span> as the Hessian of <span class="math inline">\(g.\)</span> Then</p>
<p><span class="math display">\[
\begin{aligned}
p_{ij} &amp; = {\frac{\partial}{\partial z_i}}{\frac{\partial f}{\partial z_j}} = {\frac{\partial}{\partial z_i}}\left({\frac{\partial f}{\partial x_k}}a_{kj}\right)
= \left({\frac{\partial}{\partial z_i}}{\frac{\partial f}{\partial x_k}}\right)a_{kj} \\
&amp; = \left({\frac{\partial}{\partial x_\ell}}{\frac{\partial x_\ell}{\partial z_i}}{\frac{\partial f}{\partial x_k}}\right)a_{kj}
= \left(a_{\ell i}\frac{\partial^2f}{\partial x_\ell\partial x_k}\right)a_{kj}
= a_{\ell i}h_{\ell k}a_{kj}.
\end{aligned}
\]</span></p>
<p>We can summarize this as</p>
<p><span class="math display">\[P = A^T H A.\]</span></p>
<p>Newton’s method in this context can be expressed by the two equations</p>
<p><span class="math display">\[\begin{aligned}
x^{(i+1)} &amp; = x^{(i)} - H^{-1}(x^{(i)}) \nabla f(x^{(i)}), \text{ and} \\
z^{(i+1)} &amp; = z^{(i)} - P^{-1}(z^{(i)}) \nabla g(z^{(i)}) \\
          &amp; = z^{(i)} - (A^THA)^{-1}(x^{(i)}) A^T\nabla f(x^{(i)}). \\
\end{aligned}\]</span></p>
<p>We’ll show by induction on <span class="math inline">\(i\)</span> that <span class="math inline">\(x^{(i)} = Az^{(i)}\)</span> for all <span class="math inline">\(i.\)</span> The base case for <span class="math inline">\(i=0\)</span> is true by definition. For the inductive step, assume that <span class="math inline">\(x^{(i)} = Az^{(i)},\)</span> and use the above equations to see that</p>
<p><span class="math display">\[\begin{aligned}
Az^{(i+1)} &amp; = Az^{(i)} - AA^{-1}H(x^{(i)})A^{-T}A^T\nabla f(x^{(i)}) \\
           &amp; = x^{(i)} - H(x^{(i)}) \nabla f(x^{(i)}) \\
           &amp; = x^{(i+1)},
\end{aligned}\]</span></p>
<p>which completes this part of the problem.</p>
<h3 id="part-b-2"><span class="header-section-number">1.4.2</span> Part (b)</h3>
<p>Gradient descent is not invariant to linear reparametrizations. The update equation for <span class="math inline">\(f\)</span> is</p>
<p><span class="math display">\[x^{(i+1)} = x^{(i)} - \alpha\nabla f,\]</span></p>
<p>and for <span class="math inline">\(g\)</span> is</p>
<p><span class="math display">\[z^{(i+1)} = z^{(i)} - \alpha\nabla g = z^{(i)} - \alpha A^T\nabla f.\]</span></p>
<p>In order for <span class="math inline">\(Az^{(i+1)} = x^{(i+1)},\)</span> we would need</p>
<p><span class="math display">\[A(z^{(i)} - \alpha A^T\nabla f) = Az^{(i)} - A\alpha\nabla f
\quad\Leftrightarrow\quad
AA^T\nabla f = A\nabla f,\]</span></p>
<p>but this is only guaranteed when <span class="math inline">\(A\)</span> is unitary.</p>
<h2 id="regression-for-denoising-quasar-spectra"><span class="header-section-number">1.5</span> Regression for denoising quasar spectra</h2>
<h3 id="part-a-4"><span class="header-section-number">1.5.1</span> Part (a)</h3>
<ol style="list-style-type: lower-roman">
<li></li>
</ol>
<p>Let the <span class="math inline">\(i{^\text{th}}\)</span> row of <span class="math inline">\(X\)</span> be <span class="math inline">\(x{^{(i)}}.\)</span> Then <span class="math inline">\((X{\theta})_i = \langle x{^{(i)}},{\theta}\rangle\)</span> and <span class="math inline">\((X{\theta}- y)_i = \langle x{^{(i)}}, {\theta}\rangle - y{^{(i)}}.\)</span></p>
<p>Let the <span class="math inline">\(i{^\text{th}}\)</span> diagonal element of <span class="math inline">\(W\)</span> be <span class="math inline">\(\frac{w{^{(i)}}}{2}.\)</span> Then <span class="math inline">\(((X{\theta}-y)^T W)_i = \frac{w{^{(i)}}}{2}(\langle x{^{(i)}},{\theta}\rangle-y{^{(i)}}\rangle)\)</span> so that</p>
<p><span class="math display">\[J({\theta}) = (X{\theta}- y)^T W (X{\theta}- y) =
  \sum_i \frac{w{^{(i)}}}{2}(\langle x{^{(i)}},{\theta}\rangle - y{^{(i)}})^2.\]</span></p>
<p>This gives us a nice way to express <span class="math inline">\(J({\theta})\)</span> in terms of matrices and vectors, as the problem requested.</p>
    </div>
  </body>
</html>

<!doctype html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Notes on Andrew Ng’s CS 229 Machine Learning Course</title>
    <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
    <link rel="stylesheet" href="tufte-edited.css"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
  </head>
  <body>
    <p style="display:none">\(\newcommand{\latexonlyrule}[2]{}\)</p>
    <div class="main">
      <div class="title">Notes on Andrew Ng’s CS 229 Machine Learning Course</div>
      <div class="author">Tyler Neylon</div>
      <div class="date">331.2016</div>
      <p>These are notes I’m taking as I review material from Andrew Ng’s CS 229 course on machine learning. Specifically, I’m watching <a href="https://www.youtube.com/view_play_list?p=A89DCFA6ADACE599">these videos</a> and looking at the written notes and assignments posted <a href="http://cs229.stanford.edu/materials.html">here</a>. These notes are available in two formats: <a href="http://tylerneylon.com/notes/cs229/cs229.html">html</a> and <a href="http://tylerneylon.com/notes/cs229/cs229.pdf">pdf</a>.</p>
      <p>I’ll organize these notes to correspond with the written notes from the class.</p>
      <h1 id="on-lecture-notes-1"><span class="header-section-number">1</span> On lecture notes 1</h1>
      <p>The notes in this section are based on <a href="http://cs229.stanford.edu/notes/cs229-notes1.pdf">lecture notes 1</a>.</p>
      <h2 id="gradient-descent-in-general"><span class="header-section-number">1.1</span> Gradient descent in general</h2>
      <p>Given a cost function <span class="math inline">\(J(\theta)\)</span>, the general form of an update is</p>
      <p><span class="math display">\[\theta_j := \theta_j - \alpha\frac{\partial J}{\partial \theta_j}.\]</span></p>
      <p>It bothers me that <span class="math inline">\(\alpha\)</span> is an arbitrary parameter. What is the best way to choose this parameter? Intuitively, it could be chosen based on some estimate or actual value of the second derivative of <span class="math inline">\(J\)</span>. What can be theoretically guaranteed about the rate of convergence under appropriate conditions?</p>
      <p>Why not use Newton’s method? A general guess: the second derivative of <span class="math inline">\(J\)</span> becomes cumbersome to work with.</p>
      <p>It seems worthwhile to keep my eye open for opportunities to apply improved optimization algorithms in specific cases.</p>
      <h2 id="gradient-descent-on-linear-regression"><span class="header-section-number">1.2</span> Gradient descent on linear regression</h2>
      <p>I realize this is a toy problem because linear regression in practice is not solve iteratively, but it seems worth understanding well. The general update equation is, for a single example <span class="math inline">\(i\)</span>,</p>
      <p><span class="math display">\[\theta_j := \theta_j + \alpha(y^{(i)} - h_\theta(x^{(i)}))x_j^{(i)}.\]</span></p>
      <p>The delta makes sense in that it is proportional to the error <span class="math inline">\(y-h_\theta\)</span>, and in that the sign of the product <span class="math inline">\((y-h_\theta)x\)</span> guarantees moving in the right direction. However, my first guess would be that the expression <span class="math inline">\((y-h_\theta)/x\)</span> would provide a better update.</p>
      <p>For example, suppose we have a single data point <span class="math inline">\((x, y)\)</span> where <span class="math inline">\(x\ne 0\)</span>, and a random value of <span class="math inline">\(\theta\)</span>. Then a great update would be</p>
      <p><span class="math display">\[\theta_1 := \theta_0 + (y - \theta_0 x)/x,\]</span></p>
      <p>since the next hypothesis value <span class="math inline">\(h_\theta\)</span> would then be</p>
      <p><span class="math display">\[h_\theta = \theta_1 x = \theta_0 x + y - \theta_0x = y,\]</span></p>
      <p>which is good. Another intuitive perspective is that we should be making <em>bigger</em> changes to <span class="math inline">\(\theta_j\)</span> when <span class="math inline">\(x_j\)</span> is <em>small</em>, since it’s harder to influence <span class="math inline">\(h_\theta\)</span> for such <span class="math inline">\(x\)</span> values.</p>
      <p>This is not yet a solidified intuition. I’d be interested in revisiting this question if I have time.</p>
      <h2 id="properties-of-the-trace-operator"><span class="header-section-number">1.3</span> Properties of the trace operator</h2>
      <p>The trace of a square matrix obeys the nice property that</p>
      <p><span class="math display">\[{\text{tr}\;}AB = {\text{tr}\;}BA.\qquad(1)\]</span></p>
      <p>One way to see this is to note that</p>
      <p><span class="math display">\[{\text{tr}\;}AB = a_{ij}b_{ji} = {\text{tr}\;}BA,\]</span></p>
      <p>where I’m using the informal shorthand notation that a variable repeated within a single product implies that the sum is taken over all relevant values of that variable. Specifically,</p>
      <p><span class="math display">\[a_{ij}b_{ji} \;\text{means}\; \sum_{i,j} a_{ij}b_{ji}.\]</span></p>
      <p>I wonder if there’s a more elegant way to verify (1).</p>
      <p>Ng gives other interesting trace-based equations, examined next.</p>
      <ul>
      <li>Goal: <span class="math inline">\(\quad \nabla_A{\text{tr}\;}AB = B^T.\)</span></li>
      </ul>
      <p>Since</p>
      <p><span class="math display">\[{\text{tr}\;}AB = a_{ij}b_{ji},\]</span></p>
      <p>we have that</p>
      <p><span class="math display">\[(\nabla_A{\text{tr}\;}AB)_{ij} = b_{ji},\]</span></p>
      <p>verifying the goal.</p>
      <ul>
      <li>Goal: <span class="math inline">\(\quad \nabla_{A^T}f(A) = (\nabla_A f(A))^T.\)</span></li>
      </ul>
      <p>This can be viewed as</p>
      <p><span class="math display">\[(\nabla_{A^T}f(A))_{ij} = \frac{\partial f}{\partial a_{ji}}
                                = (\nabla_A f(A))_{ji}.\]</span></p>
      <ul>
      <li>Goal: <span class="math inline">\(\quad \nabla_A\text{tr}(ABA^TC) = CAB + C^TAB^T.\)</span></li>
      </ul>
      <p>I’ll use some nonstandard index variable names below because I think it will help avoid possible confusion. Start with</p>
      <p><span class="math display">\[(ABA^TC)_{xy} = a_{xz} b_{zw} a_{vw} c_{vy}.\]</span></p>
      <p>Take the trace of that to arrive at</p>
      <p><span class="math display">\[\alpha = \text{tr}(ABA^TC) = a_{xz} b_{zw} a_{vw} c_{vx}.\]</span></p>
      <p>Use the product rule to find <span class="math inline">\(\frac{\partial\alpha}{\partial a_{ij}}\)</span>. You can think of this as, in the equation above, first setting <span class="math inline">\(xz = ij\)</span> for one part of the product rule output, and then setting <span class="math inline">\(vw = ij\)</span> for the other part. The result is</p>
      <p><span class="math display">\[(\nabla_A\alpha)_{ij} = b_{jw} a_{vw} c_{vi} + a_{xz} b_{zj} c_{ix}
                              = c_{vi} a_{vw} b_{jw} + c_{ix} a_{xz} b_{zj}.\]</span></p>
      <p>(The second equality above is based on the fact that we’re free to rearrange terms within products in the repeated-index notation being used. Such rearrangement is commutativity of numbers, not of matrices.)</p>
      <p>This last expression is exactly the <span class="math inline">\(ij^\text{th}\)</span> entry of the matrix <span class="math inline">\(CAB + C^TAB^T\)</span>, which was the goal.</p>
      <h2 id="derivation-of-the-normal-equation"><span class="header-section-number">1.4</span> Derivation of the normal equation</h2>
      <p>Ng starts with</p>
      <p><span class="math display">\[\nabla_\theta J(\theta) = \nabla_\theta\frac{1}{2}(X\theta-y)^T(X\theta-y),\]</span></p>
      <p>and uses some trace tricks to get to</p>
      <p><span class="math display">\[X^TX\theta - X^Ty.\]</span></p>
      <p>I thought that the trace tricks were not great in the sense that if I were faced with this problem it would feel like a clever trick out of thin air to use the trace (perhaps due to my own lack of experience with matrix derivatives?), and in the sense that the connection between the definition of <span class="math inline">\(J(\theta)\)</span> and the result is not clear.</p>
      <p>Next is another approach.</p>
      <p>Start with <span class="math inline">\(\nabla_\theta J(\theta) = \nabla_\theta \frac{1}{2}(\theta^TZ\theta - 2y^TX\theta);\)</span> where <span class="math inline">\(Z=X^TX\)</span>, and the doubled term is a valid combination of the two similar terms since they’re both real numbers, so we can safely take the transpose of one of them to add them together.</p>
      <p>The left term, <span class="math inline">\(\theta^T Z\theta\)</span>, can be expressed as <span class="math inline">\(w=\theta_{i1}Z_{ij}\theta_{j1}\)</span>, treating <span class="math inline">\(\theta\)</span> as an <span class="math inline">\((n+1)\times 1\)</span> matrix. Then <span class="math inline">\(({\nabla_\theta}w)_{i1} = Z_{ij}\theta_{j1} + \theta_{j1}Z_{ji}\)</span>, using the product rule; so <span class="math inline">\({\nabla_\theta}w = 2Z\theta\)</span>, using that <span class="math inline">\(Z\)</span> is symmetric.</p>
      <p>The right term, <span class="math inline">\(v = y^TX\theta = y_{i1}X_{ij}\theta_{j1}\)</span> with <span class="math inline">\(({\nabla_\theta}v)_{i1} = y_{j1}X_{ji}\)</span> so that <span class="math inline">\({\nabla_\theta}v = X^Ty\)</span>.</p>
      <p>These all lead to <span class="math inline">\({\nabla_\theta}J(\theta) = X^TX\theta - X^Ty\)</span> as before. I think it’s clearer, though, once you grok the sense that</p>
      <p><span class="math display">\[\begin{array}{rcl}
      {\nabla_\theta}\theta^TZ\theta &amp; = &amp; Z\theta + (\theta^T Z)^T, \text{and} \\
      {\nabla_\theta}u^T\theta &amp; = &amp; u, \\
      \end{array}\]</span></p>
      <p>both as intuitively straightforward matrix versions of derivative properties.</p>
      <p>I suspect this can be made even cleaner since the general product rule</p>
      <p><span class="math display">\[\nabla(f\cdot g) = (\nabla f)\cdot g + f \cdot (\nabla g)\]</span></p>
      <p>holds, even in cases where the product <span class="math inline">\(fg\)</span> is not a scalar; e.g., that it is vector- or matrix-valued. But I’m not going to dive into that right now.</p>
      <p>Also note that <span class="math inline">\(X^TX\)</span> can easily be singular. A simple example is <span class="math inline">\(X=0\)</span>, the scalar value. However, if <span class="math inline">\(X\)</span> is <span class="math inline">\(m\times n\)</span> with rank <span class="math inline">\(n\)</span>, then <span class="math inline">\(X^TXe_i = X^Tx^{(i)} \ne 0\)</span> since <span class="math inline">\(\langle x^{(i)}, x^{(i)}\rangle \ne 0.\)</span> (If <span class="math inline">\(\langle x^{(i)}, x^{(i)}\rangle = 0\)</span> then <span class="math inline">\(X\)</span> could not have rank <span class="math inline">\(n.\)</span>) So <span class="math inline">\(X^TX\)</span> is nonsingular iff <span class="math inline">\(X\)</span> has rank <span class="math inline">\(n\)</span>.</p>
      <p>Ng says something in a lecture (either 2 or 3) that implied that <span class="math inline">\((X^TX)^{-1}X^T\)</span> is <em>not</em> the pseudoinverse of <span class="math inline">\(X\)</span>, but for any real-valued full-rank matrix, it <em>is</em>.</p>
      <h2 id="a-probabilistic-motivation-for-least-squares"><span class="header-section-number">1.5</span> A probabilistic motivation for least squares</h2>
      <p>This motivation for least squares makes sense when the error is given by i.i.d. normal curves, and often this may seem like a natural assumption based on the central limit theorem.</p>
      <p>However, this same line of argument could be used to justify any cost function of the form</p>
      <p><span class="math display">\[J(\theta) = \sum_i f(\theta, x^{(i)}, y^{(i)}),\]</span></p>
      <p>where <span class="math inline">\(f\)</span> is intuitively some measure of distance between <span class="math inline">\(h_\theta(x^{(i)})\)</span> and <span class="math inline">\(y^{(i)}\)</span>. Specifically, model the error term <span class="math inline">\(\varepsilon^{(i)}\)</span> as having the probability density function <span class="math inline">\(e^{-f(\theta, x^{(i)}, y^{(i)})}\)</span>. This is intuitively reasonable when <span class="math inline">\(f\)</span> has the aforementioned distance-like property, since error values are likely near zero and unlikely far from zero. Then the log likelihood function is</p>
      <p><span class="math display">\[\ell(\theta) = \log L(\theta)
                     = \log \prod_i e^{-f(\theta, x^{(i)}, y^{(i)})}
                     = \sum_i -f(\theta, x^{(i)}, y^{(i)}),\]</span></p>
      <p>so that maximizing <span class="math inline">\(L(\theta)\)</span> is the same as minimizing the <span class="math inline">\(J(\theta)\)</span> defined in terms of this arbitrary function <span class="math inline">\(f.\)</span> To be perfectly clear, the motivation Ng provides only works when you have good reason to believe the error terms are indeed normal. At the same time, using a nice simple algorithm like least squares is quite practical even if you don’t have a great model for your error terms.</p>
      <div id="refs" class="references">
      
      </div>
    </div>
  </body>
</html>
